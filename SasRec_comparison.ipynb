{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/beomso0/ezSASRec.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-SMUdh1M5Vk",
        "outputId": "d4009947-d7d2-4d4c-caf6-4ef07a8966ce"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ezSASRec' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "PSB5KvNdmsTL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from util import filter_k_core, SASRecDataSet, load_model\n",
        "from model import SASREC\n",
        "from sampler import WarpSampler\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veNoyUNbmsTO"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "kIJU1Qa4nBOc"
      },
      "outputs": [],
      "source": [
        "path = '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGsY8SHkQ09E",
        "outputId": "98c78369-280d-417a-d668-b0f4fd55476c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "O3l-s5-BmsTP"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Competition/данные_рексис_проект/train_data.csv')\n",
        "df = df[['user_id', 'product_id']]\n",
        "df = df.rename({'user_id':'userID','product_id':'itemID'},axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/Competition/данные_рексис_проект/test_data.csv')\n",
        "df_test = df_test[['user_id', 'product_id']]\n",
        "df_test = df_test.rename({'user_id':'userID','product_id':'itemID'},axis=1)"
      ],
      "metadata": {
        "id": "eI2ruJBoY5c7"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NxqrOGxNZEAE",
        "outputId": "e95aa566-6b02-4edc-aacf-246a054c00e6"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userID  itemID\n",
              "0       5      48\n",
              "1       5      49\n",
              "2       5      50\n",
              "3       5      51\n",
              "4       5      51"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aedd6d9a-dd7f-4387-b97b-078f079dc42f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aedd6d9a-dd7f-4387-b97b-078f079dc42f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aedd6d9a-dd7f-4387-b97b-078f079dc42f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aedd6d9a-dd7f-4387-b97b-078f079dc42f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2fed3654-a9e3-4657-8123-f28437ca692f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2fed3654-a9e3-4657-8123-f28437ca692f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2fed3654-a9e3-4657-8123-f28437ca692f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter data TEEESTTT\n",
        "# every user and item will appear more than 6 times in filtered_df\n",
        "\n",
        "filtered_df_test = filter_k_core(df_test, 7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m3jZ2O_ZKu9",
        "outputId": "3d60a2c8-36b3-42cd-e4bd-e4d8011b9ed4"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: 948 users and 4391 items\n",
            "Final: 324 users and 550 items\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make maps (encoder) TEEESSSSTTTTT\n",
        "\n",
        "user_set, item_set = set(filtered_df_test['userID'].unique()), set(filtered_df_test['itemID'].unique())\n",
        "user_map = dict()\n",
        "item_map = dict()\n",
        "for u, user in enumerate(user_set):\n",
        "    user_map[user] = u+1\n",
        "for i, item in enumerate(item_set):\n",
        "    item_map[item] = i+1\n",
        "\n",
        "maps = (user_map, item_map)"
      ],
      "metadata": {
        "id": "9w0sjsPmZRBr"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode filtered_df TESTT\n",
        "\n",
        "filtered_df_test[\"userID\"] = filtered_df_test[\"userID\"].apply(lambda x: user_map[x])\n",
        "filtered_df_test[\"itemID\"] = filtered_df_test[\"itemID\"].apply(lambda x: item_map[x])\n",
        "filtered_df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "juAdTUeEZY_W",
        "outputId": "55fb49a3-c056-4d80-8586-59317dfffd49"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       userID  itemID\n",
              "0           2      33\n",
              "1           2      34\n",
              "2           2      35\n",
              "9           2      38\n",
              "17          2      40\n",
              "...       ...     ...\n",
              "19726     297     434\n",
              "19729     297       2\n",
              "19731     297      24\n",
              "19733     297     445\n",
              "19767     297     328\n",
              "\n",
              "[8302 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10abd685-1142-41ff-8478-0143e768670d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19726</th>\n",
              "      <td>297</td>\n",
              "      <td>434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19729</th>\n",
              "      <td>297</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19731</th>\n",
              "      <td>297</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19733</th>\n",
              "      <td>297</td>\n",
              "      <td>445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19767</th>\n",
              "      <td>297</td>\n",
              "      <td>328</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8302 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10abd685-1142-41ff-8478-0143e768670d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-10abd685-1142-41ff-8478-0143e768670d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-10abd685-1142-41ff-8478-0143e768670d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ecb6207e-c762-4bbd-8e31-700c6368b7c0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ecb6207e-c762-4bbd-8e31-700c6368b7c0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ecb6207e-c762-4bbd-8e31-700c6368b7c0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save data and maps TEST\n",
        "# save sasrec data\n",
        "filtered_df_test.to_csv('sasrec_data_test.txt', sep=\"\\t\", header=False, index=False)\n",
        "\n",
        "# save maps\n",
        "with open('maps.pkl','wb') as f:\n",
        "    pickle.dump(maps, f)"
      ],
      "metadata": {
        "id": "EGXGJAtMaCCW"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "\n",
        "data_test = SASRecDataSet('sasrec_data_test.txt')\n",
        "data_test.split() # train, val, test split\n",
        "              # the last interactions of each user is used for test\n",
        "              # the last but one will be used for validation\n",
        "              # others will be used for train"
      ],
      "metadata": {
        "id": "-doYEG2JaFPK"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uSUrvrb0msTQ",
        "outputId": "78d46ba9-a681-4da4-fae3-7bef1dfe4cae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userID  itemID\n",
              "0       1       1\n",
              "1       1       2\n",
              "2       1       3\n",
              "3       1       4\n",
              "4       1       5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4b10aa6-f9fe-4474-86fa-40895672c7e4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4b10aa6-f9fe-4474-86fa-40895672c7e4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4b10aa6-f9fe-4474-86fa-40895672c7e4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4b10aa6-f9fe-4474-86fa-40895672c7e4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b4d5bf2f-aef3-4f63-b395-d729df598f3e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4d5bf2f-aef3-4f63-b395-d729df598f3e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b4d5bf2f-aef3-4f63-b395-d729df598f3e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz7t-JucmsTR",
        "outputId": "50e61266-b968-416b-80f2-9d15bce9c33e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: 9040 users and 9443 items\n",
            "Final: 6346 users and 4030 items\n"
          ]
        }
      ],
      "source": [
        "# filter data\n",
        "# every user and item will appear more than 6 times in filtered_df\n",
        "\n",
        "filtered_df = filter_k_core(df, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "AbaCZJMhmsTR"
      },
      "outputs": [],
      "source": [
        "# make maps (encoder)\n",
        "\n",
        "user_set, item_set = set(filtered_df['userID'].unique()), set(filtered_df['itemID'].unique())\n",
        "user_map = dict()\n",
        "item_map = dict()\n",
        "for u, user in enumerate(user_set):\n",
        "    user_map[user] = u+1\n",
        "for i, item in enumerate(item_set):\n",
        "    item_map[item] = i+1\n",
        "\n",
        "maps = (user_map, item_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "vllIRub3msTS"
      },
      "outputs": [],
      "source": [
        "# Encode filtered_df\n",
        "\n",
        "filtered_df[\"userID\"] = filtered_df[\"userID\"].apply(lambda x: user_map[x])\n",
        "filtered_df[\"itemID\"] = filtered_df[\"itemID\"].apply(lambda x: item_map[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "b1iIW19gmsTS"
      },
      "outputs": [],
      "source": [
        "# save data and maps\n",
        "\n",
        "# save sasrec data\n",
        "filtered_df.to_csv('sasrec_data.txt', sep=\"\\t\", header=False, index=False)\n",
        "\n",
        "# save maps\n",
        "with open('maps.pkl','wb') as f:\n",
        "    pickle.dump(maps, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL2GMXOVmsTT"
      },
      "source": [
        "# Load data and Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "bpX3mF-MmsTT"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "\n",
        "data = SASRecDataSet('sasrec_data.txt')\n",
        "data.split() # train, val, test split\n",
        "              # the last interactions of each user is used for test\n",
        "              # the last but one will be used for validation\n",
        "              # others will be used for train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "OSSSKsMhmsTU"
      },
      "outputs": [],
      "source": [
        "# make model and warmsampler for batch training\n",
        "\n",
        "max_len = 100\n",
        "hidden_units = 128\n",
        "batch_size = 2048\n",
        "\n",
        "model = SASREC(\n",
        "    item_num=data.itemnum,\n",
        "    seq_max_len=max_len,\n",
        "    num_blocks=2,\n",
        "    embedding_dim=hidden_units,\n",
        "    attention_dim=hidden_units,\n",
        "    attention_num_heads=2,\n",
        "    dropout_rate=0.2,\n",
        "    conv_dims = [hidden_units, hidden_units],\n",
        "    l2_reg=0.00001\n",
        ")\n",
        "\n",
        "sampler = WarpSampler(data.user_train, data.usernum, data.itemnum, batch_size=batch_size, maxlen=max_len, n_workers=multiprocessing.cpu_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhmZdD1VmsTU",
        "outputId": "0667e691-eaac-4d58-a37b-dc59d023dfd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 3 -----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, test (NDCG@10: 0.1907434603986771, HR@10: 0.194)\n",
            "best score model updated and saved\n",
            "epoch 2 / 3 -----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2, test (NDCG@10: 0.18982231189368404, HR@10: 0.201)\n",
            "best score model updated and saved\n",
            "epoch 3 / 3 -----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 3, test (NDCG@10: 0.13756396327830617, HR@10: 0.172)\n"
          ]
        }
      ],
      "source": [
        "# train model\n",
        "\n",
        "model.train(\n",
        "          data,\n",
        "          sampler,\n",
        "          num_epochs=3,\n",
        "          batch_size=batch_size,\n",
        "          lr=0.001,\n",
        "          val_epoch=1,\n",
        "          val_target_user_n=1000,\n",
        "          target_item_n=-1,\n",
        "          auto_save=True,\n",
        "          path = path,\n",
        "          exp_name='exp_example',\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6STwesynv-J"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "3Y-QK-kUskN_"
      },
      "outputs": [],
      "source": [
        "# load trained model\n",
        "\n",
        "model = load_model(path,'exp_example')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import UserDict\n",
        "from itertools import count\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    - Q (query), K (key) and V (value) are split into multiple heads (num_heads)\n",
        "    - each tuple (q, k, v) are fed to scaled_dot_product_attention\n",
        "    - all attention outputs are concatenated\n",
        "\n",
        "    Args:\n",
        "            attention_dim (int): Dimension of the attention embeddings.\n",
        "            num_heads (int): Number of heads in the multi-head self-attention module.\n",
        "            dropout_rate (float): Dropout probability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, attention_dim, num_heads, dropout_rate):\n",
        "\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_dim = attention_dim\n",
        "        assert attention_dim % self.num_heads == 0\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.depth = attention_dim // self.num_heads\n",
        "\n",
        "        self.Q = tf.keras.layers.Dense(self.attention_dim, activation=None)\n",
        "        self.K = tf.keras.layers.Dense(self.attention_dim, activation=None)\n",
        "        self.V = tf.keras.layers.Dense(self.attention_dim, activation=None)\n",
        "        self.dropout = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "\n",
        "    def call(self, queries, keys):\n",
        "        \"\"\"Model forward pass.\n",
        "\n",
        "        Args:\n",
        "            queries (tf.Tensor): Tensor of queries.\n",
        "            keys (tf.Tensor): Tensor of keys\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Output tensor\n",
        "        \"\"\"\n",
        "\n",
        "        # Linear projections\n",
        "        Q = self.Q(queries)  # (N, T_q, C)\n",
        "        K = self.K(keys)  # (N, T_k, C)\n",
        "        V = self.V(keys)  # (N, T_k, C)\n",
        "\n",
        "        # --- MULTI HEAD ---\n",
        "        # Split and concat, Q_, K_ and V_ are all (h*N, T_q, C/h)\n",
        "        Q_ = tf.concat(tf.split(Q, self.num_heads, axis=2), axis=0)\n",
        "        K_ = tf.concat(tf.split(K, self.num_heads, axis=2), axis=0)\n",
        "        V_ = tf.concat(tf.split(V, self.num_heads, axis=2), axis=0)\n",
        "\n",
        "        # --- SCALED DOT PRODUCT ---\n",
        "        # Multiplication\n",
        "        outputs = tf.matmul(Q_, tf.transpose(K_, [0, 2, 1]))  # (h*N, T_q, T_k)\n",
        "\n",
        "        # Scale\n",
        "        outputs = outputs / (K_.get_shape().as_list()[-1] ** 0.5)\n",
        "\n",
        "        # Key Masking\n",
        "        key_masks = tf.sign(tf.abs(tf.reduce_sum(keys, axis=-1)))  # (N, T_k)\n",
        "        key_masks = tf.tile(key_masks, [self.num_heads, 1])  # (h*N, T_k)\n",
        "        key_masks = tf.tile(\n",
        "            tf.expand_dims(key_masks, 1), [1, tf.shape(queries)[1], 1]\n",
        "        )  # (h*N, T_q, T_k)\n",
        "\n",
        "        paddings = tf.ones_like(outputs) * (-(2 ** 32) + 1)\n",
        "        # outputs, (h*N, T_q, T_k)\n",
        "        outputs = tf.where(tf.equal(key_masks, 0), paddings, outputs)\n",
        "\n",
        "        # Future blinding (Causality)\n",
        "        diag_vals = tf.ones_like(outputs[0, :, :])  # (T_q, T_k)\n",
        "        tril = tf.linalg.LinearOperatorLowerTriangular(\n",
        "            diag_vals\n",
        "        ).to_dense()  # (T_q, T_k)\n",
        "        masks = tf.tile(\n",
        "            tf.expand_dims(tril, 0), [tf.shape(outputs)[0], 1, 1]\n",
        "        )  # (h*N, T_q, T_k)\n",
        "\n",
        "        paddings = tf.ones_like(masks) * (-(2 ** 32) + 1)\n",
        "        # outputs, (h*N, T_q, T_k)\n",
        "        outputs = tf.where(tf.equal(masks, 0), paddings, outputs)\n",
        "\n",
        "        # Activation\n",
        "        outputs = tf.nn.softmax(outputs)  # (h*N, T_q, T_k)\n",
        "\n",
        "        # Query Masking, query_masks (N, T_q)\n",
        "        query_masks = tf.sign(tf.abs(tf.reduce_sum(queries, axis=-1)))\n",
        "        query_masks = tf.tile(query_masks, [self.num_heads, 1])  # (h*N, T_q)\n",
        "        query_masks = tf.tile(\n",
        "            tf.expand_dims(query_masks, -1), [1, 1, tf.shape(keys)[1]]\n",
        "        )  # (h*N, T_q, T_k)\n",
        "        outputs *= query_masks  # broadcasting. (N, T_q, C)\n",
        "\n",
        "        # Dropouts\n",
        "        outputs = self.dropout(outputs)\n",
        "\n",
        "        # Weighted sum\n",
        "        outputs = tf.matmul(outputs, V_)  # ( h*N, T_q, C/h)\n",
        "\n",
        "        # --- MULTI HEAD ---\n",
        "        # concat heads\n",
        "        outputs = tf.concat(\n",
        "            tf.split(outputs, self.num_heads, axis=0), axis=2\n",
        "        )  # (N, T_q, C)\n",
        "\n",
        "        # Residual connection\n",
        "        outputs += queries\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class PointWiseFeedForward(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Convolution layers with residual connection\n",
        "\n",
        "    Args:\n",
        "            conv_dims (list): List of the dimensions of the Feedforward layer.\n",
        "            dropout_rate (float): Dropout probability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, conv_dims, dropout_rate):\n",
        "        super(PointWiseFeedForward, self).__init__()\n",
        "        self.conv_dims = conv_dims\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.conv_layer1 = tf.keras.layers.Conv1D(\n",
        "            filters=self.conv_dims[0], kernel_size=1, activation=\"relu\", use_bias=True\n",
        "        )\n",
        "        self.conv_layer2 = tf.keras.layers.Conv1D(\n",
        "            filters=self.conv_dims[1], kernel_size=1, activation=None, use_bias=True\n",
        "        )\n",
        "        self.dropout_layer = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"Model forward pass.\n",
        "\n",
        "        Args:\n",
        "            x (tf.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Output tensor\n",
        "        \"\"\"\n",
        "\n",
        "        output = self.conv_layer1(x)\n",
        "        output = self.dropout_layer(output)\n",
        "\n",
        "        output = self.conv_layer2(output)\n",
        "        output = self.dropout_layer(output)\n",
        "\n",
        "        # Residual connection\n",
        "        output += x\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Transformer based encoder layer\n",
        "\n",
        "    Args:\n",
        "            seq_max_len (int): Maximum sequence length.\n",
        "            embedding_dim (int): Embedding dimension.\n",
        "            attention_dim (int): Dimension of the attention embeddings.\n",
        "            num_heads (int): Number of heads in the multi-head self-attention module.\n",
        "            conv_dims (list): List of the dimensions of the Feedforward layer.\n",
        "            dropout_rate (float): Dropout probability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        seq_max_len,\n",
        "        embedding_dim,\n",
        "        attention_dim,\n",
        "        num_heads,\n",
        "        conv_dims,\n",
        "        dropout_rate,\n",
        "    ):\n",
        "        \"\"\"Initialize parameters.\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.seq_max_len = seq_max_len\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.mha = MultiHeadAttention(attention_dim, num_heads, dropout_rate)\n",
        "        self.ffn = PointWiseFeedForward(conv_dims, dropout_rate)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "        self.layer_normalization = LayerNormalization(\n",
        "            self.seq_max_len, self.embedding_dim, 1e-08\n",
        "        )\n",
        "\n",
        "    def call_(self, x, training, mask):\n",
        "        \"\"\"Model forward pass.\n",
        "\n",
        "        Args:\n",
        "            x (tf.Tensor): Input tensor.\n",
        "            training (tf.Tensor): Training tensor.\n",
        "            mask (tf.Tensor): Mask tensor.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Output tensor\n",
        "        \"\"\"\n",
        "\n",
        "        attn_output = self.mha(queries=self.layer_normalization(x), keys=x)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        # feed forward network\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(\n",
        "            out1 + ffn_output\n",
        "        )  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        # masking\n",
        "        out2 *= mask\n",
        "\n",
        "        return out2\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        \"\"\"Model forward pass.\n",
        "\n",
        "        Args:\n",
        "            x (tf.Tensor): Input tensor.\n",
        "            training (tf.Tensor): Training tensor.\n",
        "            mask (tf.Tensor): Mask tensor.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Output tensor\n",
        "        \"\"\"\n",
        "\n",
        "        x_norm = self.layer_normalization(x)\n",
        "        attn_output = self.mha(queries=x_norm, keys=x)\n",
        "        attn_output = self.ffn(attn_output)\n",
        "        out = attn_output * mask\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Invokes Transformer based encoder with user defined number of layers\n",
        "\n",
        "    Args:\n",
        "            num_layers (int): Number of layers.\n",
        "            seq_max_len (int): Maximum sequence length.\n",
        "            embedding_dim (int): Embedding dimension.\n",
        "            attention_dim (int): Dimension of the attention embeddings.\n",
        "            num_heads (int): Number of heads in the multi-head self-attention module.\n",
        "            conv_dims (list): List of the dimensions of the Feedforward layer.\n",
        "            dropout_rate (float): Dropout probability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        seq_max_len,\n",
        "        embedding_dim,\n",
        "        attention_dim,\n",
        "        num_heads,\n",
        "        conv_dims,\n",
        "        dropout_rate,\n",
        "    ):\n",
        "        \"\"\"Initialize parameters.\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.enc_layers = [\n",
        "            EncoderLayer(\n",
        "                seq_max_len,\n",
        "                embedding_dim,\n",
        "                attention_dim,\n",
        "                num_heads,\n",
        "                conv_dims,\n",
        "                dropout_rate,\n",
        "            )\n",
        "            for _ in range(num_layers)\n",
        "        ]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        \"\"\"Model forward pass.\n",
        "\n",
        "        Args:\n",
        "            x (tf.Tensor): Input tensor.\n",
        "            training (tf.Tensor): Training tensor.\n",
        "            mask (tf.Tensor): Mask tensor.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Output tensor\n",
        "        \"\"\"\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "\n",
        "class LayerNormalization(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    Layer normalization using mean and variance\n",
        "    gamma and beta are the learnable parameters\n",
        "\n",
        "    Args:\n",
        "            seq_max_len (int): Maximum sequence length.\n",
        "            embedding_dim (int): Embedding dimension.\n",
        "            epsilon (float): Epsilon value.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, seq_max_len, embedding_dim, epsilon):\n",
        "        \"\"\"Initialize parameters.\n",
        "\n",
        "        Args:\n",
        "            seq_max_len (int): Maximum sequence length.\n",
        "            embedding_dim (int): Embedding dimension.\n",
        "            epsilon (float): Epsilon value.\n",
        "        \"\"\"\n",
        "        super(LayerNormalization, self).__init__()\n",
        "        self.seq_max_len = seq_max_len\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.epsilon = epsilon\n",
        "        self.params_shape = (self.seq_max_len, self.embedding_dim)\n",
        "        g_init = tf.ones_initializer()\n",
        "        self.gamma = tf.Variable(\n",
        "            initial_value=g_init(shape=self.params_shape, dtype=\"float32\"),\n",
        "            trainable=True,\n",
        "        )\n",
        "        b_init = tf.zeros_initializer()\n",
        "        self.beta = tf.Variable(\n",
        "            initial_value=b_init(shape=self.params_shape, dtype=\"float32\"),\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"Model forward pass.\n",
        "\n",
        "        Args:\n",
        "            x (tf.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Output tensor\n",
        "        \"\"\"\n",
        "        mean, variance = tf.nn.moments(x, [-1], keepdims=True)\n",
        "        normalized = (x - mean) / ((variance + self.epsilon) ** 0.5)\n",
        "        output = self.gamma * normalized + self.beta\n",
        "        return output\n",
        "\n",
        "\n",
        "class SASREC(tf.keras.Model):\n",
        "    \"\"\"Self-Attentive Sequential Recommendation Using Transformer\n",
        "\n",
        "    Keyword Args:\n",
        "        item_num (int): Number of items in the dataset.\n",
        "        seq_max_len (int): Maximum number of items in user history.\n",
        "        num_blocks (int): Number of Transformer blocks to be used.\n",
        "        embedding_dim (int): Item embedding dimension.\n",
        "        attention_dim (int): Transformer attention dimension.\n",
        "        attention_num_heads (int): Transformer attention head.\n",
        "        conv_dims (list): List of the dimensions of the Feedforward layer.\n",
        "        dropout_rate (float): Dropout rate.\n",
        "        l2_reg (float): Coefficient of the L2 regularization.\n",
        "\n",
        "    Attributes:\n",
        "        epoch (int): Epoch of trained model.\n",
        "        best_score (float): Best validation HR@10 score while training.\n",
        "        val_users (list): User list for validation.\n",
        "        history (pd.DataFrame): Train history containing epoch, NDCG@10, and HR@10.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "\n",
        "        super(SASREC, self).__init__()\n",
        "\n",
        "        self.epoch = 0\n",
        "        self.best_score=0\n",
        "        self.val_users = []\n",
        "        self.history = pd.DataFrame(columns=['epoch','NDCG@10','HR@10'])\n",
        "\n",
        "        self.item_num = kwargs.get(\"item_num\", None)\n",
        "        self.seq_max_len = kwargs.get(\"seq_max_len\", 100)\n",
        "        self.num_blocks = kwargs.get(\"num_blocks\", 2)\n",
        "        self.embedding_dim = kwargs.get(\"embedding_dim\", 100)\n",
        "        self.attention_dim = kwargs.get(\"attention_dim\", 100)\n",
        "        self.attention_num_heads = kwargs.get(\"attention_num_heads\", 1)\n",
        "        self.conv_dims = kwargs.get(\"conv_dims\", [100, 100])\n",
        "        self.dropout_rate = kwargs.get(\"dropout_rate\", 0.5)\n",
        "        self.l2_reg = kwargs.get(\"l2_reg\", 0.0)\n",
        "\n",
        "        self.item_embedding_layer = tf.keras.layers.Embedding(\n",
        "            self.item_num + 1,\n",
        "            self.embedding_dim,\n",
        "            name=\"item_embeddings\",\n",
        "            mask_zero=True,\n",
        "            embeddings_regularizer=tf.keras.regularizers.L2(self.l2_reg),\n",
        "        )\n",
        "\n",
        "        self.positional_embedding_layer = tf.keras.layers.Embedding(\n",
        "            self.seq_max_len,\n",
        "            self.embedding_dim,\n",
        "            name=\"positional_embeddings\",\n",
        "            mask_zero=False,\n",
        "            embeddings_regularizer=tf.keras.regularizers.L2(self.l2_reg),\n",
        "        )\n",
        "        self.dropout_layer = tf.keras.layers.Dropout(self.dropout_rate)\n",
        "        self.encoder = Encoder(\n",
        "            self.num_blocks,\n",
        "            self.seq_max_len,\n",
        "            self.embedding_dim,\n",
        "            self.attention_dim,\n",
        "            self.attention_num_heads,\n",
        "            self.conv_dims,\n",
        "            self.dropout_rate,\n",
        "        )\n",
        "        self.mask_layer = tf.keras.layers.Masking(mask_value=0)\n",
        "        self.layer_normalization = LayerNormalization(\n",
        "            self.seq_max_len, self.embedding_dim, 1e-08\n",
        "        )\n",
        "\n",
        "    def embedding(self, input_seq):\n",
        "        \"\"\"Compute the sequence and positional embeddings.\n",
        "\n",
        "        Args:\n",
        "            input_seq (tf.Tensor): Input sequence\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Sequence embeddings\n",
        "            tf.Tensor: Positional embeddings\n",
        "        \"\"\"\n",
        "\n",
        "        seq_embeddings = self.item_embedding_layer(input_seq)\n",
        "        seq_embeddings = seq_embeddings * (self.embedding_dim ** 0.5)\n",
        "\n",
        "        # FIXME\n",
        "        positional_seq = tf.expand_dims(tf.range(tf.shape(input_seq)[1]), 0)\n",
        "        positional_seq = tf.tile(positional_seq, [tf.shape(input_seq)[0], 1])\n",
        "        positional_embeddings = self.positional_embedding_layer(positional_seq)\n",
        "\n",
        "        return seq_embeddings, positional_embeddings\n",
        "\n",
        "    def call(self, x, training):\n",
        "        \"\"\"Model forward pass.\n",
        "\n",
        "        Args:\n",
        "            x (tf.Tensor): Input tensor.\n",
        "            training (tf.Tensor): Training tensor.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Logits of the positive examples\n",
        "            tf.Tensor: Logits of the negative examples\n",
        "            tf.Tensor: Mask for nonzero targets\n",
        "        \"\"\"\n",
        "\n",
        "        input_seq = x[\"input_seq\"]\n",
        "        pos = x[\"positive\"]\n",
        "        neg = x[\"negative\"]\n",
        "\n",
        "        mask = tf.expand_dims(tf.cast(tf.not_equal(input_seq, 0), tf.float32), -1)\n",
        "        seq_embeddings, positional_embeddings = self.embedding(input_seq)\n",
        "\n",
        "        # add positional embeddings\n",
        "        seq_embeddings += positional_embeddings\n",
        "\n",
        "        # dropout\n",
        "        seq_embeddings = self.dropout_layer(seq_embeddings)\n",
        "\n",
        "        # masking\n",
        "        seq_embeddings *= mask\n",
        "\n",
        "        # --- ATTENTION BLOCKS ---\n",
        "        seq_attention = seq_embeddings\n",
        "        seq_attention = self.encoder(seq_attention, training, mask)\n",
        "        seq_attention = self.layer_normalization(seq_attention)  # (b, s, d)\n",
        "\n",
        "        # --- PREDICTION LAYER ---\n",
        "        # user's sequence embedding\n",
        "        pos = self.mask_layer(pos)\n",
        "        neg = self.mask_layer(neg)\n",
        "\n",
        "        pos = tf.reshape(pos, [tf.shape(input_seq)[0] * self.seq_max_len])\n",
        "        neg = tf.reshape(neg, [tf.shape(input_seq)[0] * self.seq_max_len])\n",
        "        pos_emb = self.item_embedding_layer(pos)\n",
        "        neg_emb = self.item_embedding_layer(neg)\n",
        "        seq_emb = tf.reshape(\n",
        "            seq_attention,\n",
        "            [tf.shape(input_seq)[0] * self.seq_max_len, self.embedding_dim],\n",
        "        )  # (b*s, d)\n",
        "\n",
        "        pos_logits = tf.reduce_sum(pos_emb * seq_emb, -1)\n",
        "        neg_logits = tf.reduce_sum(neg_emb * seq_emb, -1)\n",
        "\n",
        "        pos_logits = tf.expand_dims(pos_logits, axis=-1)  # (bs, 1)\n",
        "        # pos_prob = tf.keras.layers.Dense(1, activation='sigmoid')(pos_logits)  # (bs, 1)\n",
        "\n",
        "        neg_logits = tf.expand_dims(neg_logits, axis=-1)  # (bs, 1)\n",
        "        # neg_prob = tf.keras.layers.Dense(1, activation='sigmoid')(neg_logits)  # (bs, 1)\n",
        "\n",
        "        # output = tf.concat([pos_logits, neg_logits], axis=0)\n",
        "\n",
        "        # masking for loss calculation\n",
        "        istarget = tf.reshape(\n",
        "            tf.cast(tf.not_equal(pos, 0), dtype=tf.float32),\n",
        "            [tf.shape(input_seq)[0] * self.seq_max_len],\n",
        "        )\n",
        "\n",
        "        return pos_logits, neg_logits, istarget\n",
        "\n",
        "    def predict(self, inputs,neg_cand_n):\n",
        "        \"\"\"Returns the logits for the test items.\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): Input tensor.\n",
        "            neg_cand_n: num of negative candidates\n",
        "        Returns:\n",
        "            tf.Tensor:Output tensor\n",
        "        \"\"\"\n",
        "        training = False\n",
        "        input_seq = inputs[\"input_seq\"]\n",
        "        candidate = inputs[\"candidate\"]\n",
        "\n",
        "        mask = tf.expand_dims(tf.cast(tf.not_equal(input_seq, 0), tf.float32), -1)\n",
        "        seq_embeddings, positional_embeddings = self.embedding(input_seq)\n",
        "        seq_embeddings += positional_embeddings\n",
        "        # seq_embeddings = self.dropout_layer(seq_embeddings)\n",
        "        seq_embeddings *= mask\n",
        "        seq_attention = seq_embeddings\n",
        "        seq_attention = self.encoder(seq_attention, training, mask)\n",
        "        seq_attention = self.layer_normalization(seq_attention)  # (b, s, d)\n",
        "        seq_emb = tf.reshape(\n",
        "            seq_attention,\n",
        "            [tf.shape(input_seq)[0] * self.seq_max_len, self.embedding_dim],\n",
        "        )  # (b*s, d)\n",
        "        # print(candidate)\n",
        "        candidate_emb = self.item_embedding_layer(candidate)  # (b, s, d)\n",
        "        candidate_emb = tf.transpose(candidate_emb, perm=[0, 2, 1])  # (b, d, s)\n",
        "\n",
        "        test_logits = tf.matmul(seq_emb, candidate_emb)\n",
        "        # (200, 100) * (1, 101, 100)'\n",
        "\n",
        "        test_logits = tf.reshape(\n",
        "            test_logits,\n",
        "            [tf.shape(input_seq)[0], self.seq_max_len, 1+neg_cand_n],\n",
        "        )  # (1, 50, 1+neg_can)\n",
        "        test_logits = test_logits[:, -1, :]  # (1, 101)\n",
        "        return test_logits\n",
        "\n",
        "    def loss_function(self, pos_logits, neg_logits, istarget):\n",
        "        \"\"\"Losses are calculated separately for the positive and negative\n",
        "        items based on the corresponding logits. A mask is included to\n",
        "        take care of the zero items (added for padding).\n",
        "\n",
        "        Args:\n",
        "            pos_logits (tf.Tensor): Logits of the positive examples.\n",
        "            neg_logits (tf.Tensor): Logits of the negative examples.\n",
        "            istarget (tf.Tensor): Mask for nonzero targets.\n",
        "\n",
        "        Returns:\n",
        "            float: loss\n",
        "        \"\"\"\n",
        "\n",
        "        pos_logits = pos_logits[:, 0]\n",
        "        neg_logits = neg_logits[:, 0]\n",
        "\n",
        "        # ignore padding items (0)\n",
        "        # istarget = tf.reshape(\n",
        "        #     tf.cast(tf.not_equal(self.pos, 0), dtype=tf.float32),\n",
        "        #     [tf.shape(self.input_seq)[0] * self.seq_max_len],\n",
        "        # )\n",
        "        # for logits\n",
        "        loss = tf.reduce_sum(\n",
        "            -tf.math.log(tf.math.sigmoid(pos_logits) + 1e-24) * istarget\n",
        "            - tf.math.log(1 - tf.math.sigmoid(neg_logits) + 1e-24) * istarget\n",
        "        ) / tf.reduce_sum(istarget)\n",
        "\n",
        "        # for probabilities\n",
        "        # loss = tf.reduce_sum(\n",
        "        #         - tf.math.log(pos_logits + 1e-24) * istarget -\n",
        "        #         tf.math.log(1 - neg_logits + 1e-24) * istarget\n",
        "        # ) / tf.reduce_sum(istarget)\n",
        "        reg_loss = tf.compat.v1.losses.get_regularization_loss()\n",
        "        # reg_losses = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.REGULARIZATION_LOSSES)\n",
        "        # loss += sum(reg_losses)\n",
        "        loss += reg_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def create_combined_dataset(self, u, seq, pos, neg):\n",
        "        \"\"\"\n",
        "        function to create model inputs from sampled batch data.\n",
        "        This function is used during training.\n",
        "        \"\"\"\n",
        "        inputs = {}\n",
        "        seq = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            seq, padding=\"pre\", truncating=\"pre\", maxlen=self.seq_max_len\n",
        "        )\n",
        "        pos = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            pos, padding=\"pre\", truncating=\"pre\", maxlen=self.seq_max_len\n",
        "        )\n",
        "        neg = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            neg, padding=\"pre\", truncating=\"pre\", maxlen=self.seq_max_len\n",
        "        )\n",
        "\n",
        "        inputs[\"users\"] = np.expand_dims(np.array(u), axis=-1)\n",
        "        inputs[\"input_seq\"] = seq\n",
        "        inputs[\"positive\"] = pos\n",
        "        inputs[\"negative\"] = neg\n",
        "\n",
        "        target = np.concatenate(\n",
        "            [\n",
        "                np.repeat(1, seq.shape[0] * seq.shape[1]),\n",
        "                np.repeat(0, seq.shape[0] * seq.shape[1]),\n",
        "            ],\n",
        "            axis=0,\n",
        "        )\n",
        "        target = np.expand_dims(target, axis=-1)\n",
        "        return inputs, target\n",
        "\n",
        "    def train(self, dataset, sampler, num_epochs=10,batch_size=128,lr=0.001,\\\n",
        "            val_epoch=5,val_target_user_n=1000,target_item_n=-1,auto_save=False,\\\n",
        "            path='./',exp_name='SASRec_exp'):\n",
        "\n",
        "        \"\"\"High level function for model training as well as evaluation on the validation and test dataset\n",
        "\n",
        "        Args:\n",
        "            dataset (:obj:`util.SASRecDataSet`): SASRecDataSet containing users-item interaction history.\n",
        "            sampler (:obj:`util.WarpSampler`): WarpSampler.\n",
        "            num_epochs (int, optional): Epoch. Defaults to 10.\n",
        "            batch_size (int, optional): Batch size. Defaults to 128.\n",
        "            lr (float, optional): Learning rate. Defaults to 0.001.\n",
        "            val_epoch (int, optional): Validation term. Defaults to 5.\n",
        "            val_target_user_n (int, optional): Number of randomly sampled users to conduct validation. Defaults to 1000.\n",
        "            target_item_n (int, optional): Size of candidate. Defaults to -1, which means all.\n",
        "            auto_save (bool, optional): If true, save model with best validation score. Defaults to False.\n",
        "            path (str, optional): Path to save model.\n",
        "            exp_name (str, optional): Experiment name.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        num_steps = int(len(dataset.user_train) / batch_size)\n",
        "\n",
        "        optimizer = tf.keras.optimizers.Adam(\n",
        "            learning_rate=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-7\n",
        "        )\n",
        "\n",
        "        loss_function = self.loss_function\n",
        "\n",
        "        train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "\n",
        "        train_step_signature = [\n",
        "            {\n",
        "                \"users\": tf.TensorSpec(shape=(None, 1), dtype=tf.int64),\n",
        "                \"input_seq\": tf.TensorSpec(\n",
        "                    shape=(None, self.seq_max_len), dtype=tf.int64\n",
        "                ),\n",
        "                \"positive\": tf.TensorSpec(\n",
        "                    shape=(None, self.seq_max_len), dtype=tf.int64\n",
        "                ),\n",
        "                \"negative\": tf.TensorSpec(\n",
        "                    shape=(None, self.seq_max_len), dtype=tf.int64\n",
        "                ),\n",
        "            },\n",
        "            tf.TensorSpec(shape=(None, 1), dtype=tf.int64),\n",
        "        ]\n",
        "\n",
        "        @tf.function(input_signature=train_step_signature)\n",
        "        def train_step(inp, tar):\n",
        "            with tf.GradientTape() as tape:\n",
        "                pos_logits, neg_logits, loss_mask = self(inp, training=True)\n",
        "                loss = loss_function(pos_logits, neg_logits, loss_mask)\n",
        "\n",
        "            gradients = tape.gradient(loss, self.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "            train_loss(loss)\n",
        "            return loss\n",
        "\n",
        "\n",
        "\n",
        "        for epoch in range(1, num_epochs + 1):\n",
        "\n",
        "            print(f'epoch {epoch} / {num_epochs} -----------------------------')\n",
        "\n",
        "            self.epoch = epoch\n",
        "            step_loss = []\n",
        "            train_loss.reset_states()\n",
        "            for step in tqdm(\n",
        "                range(num_steps), total=num_steps, ncols=70, leave=False, unit=\"b\",\n",
        "                # disable= ~progress_bar\n",
        "            ):\n",
        "\n",
        "                u, seq, pos, neg = sampler.next_batch()\n",
        "\n",
        "                inputs, target = self.create_combined_dataset(u, seq, pos, neg)\n",
        "\n",
        "                loss = train_step(inputs, target)\n",
        "                step_loss.append(loss)\n",
        "\n",
        "            if epoch % val_epoch == 0:\n",
        "                print(\"Evaluating...\")\n",
        "                t_test = self.evaluate(dataset,target_user_n=val_target_user_n,target_item_n=target_item_n,is_val=True)\n",
        "                print(\n",
        "                    f\"epoch: {epoch}, test (NDCG@10: {t_test[0]}, HR@10: {t_test[1]})\"\n",
        "                )\n",
        "                self.history.loc[len(self.history)] = [epoch,t_test[0],t_test[1]]\n",
        "\n",
        "                if t_test[1] > self.best_score:\n",
        "                    self.best_score = t_test[1]\n",
        "                    if auto_save:\n",
        "                        self.save(path,exp_name)\n",
        "                        print('best score model updated and saved')\n",
        "\n",
        "        if auto_save:\n",
        "            self.history.to_csv(f'{path}/{exp_name}/{exp_name}_train_log.csv',index=False)\n",
        "\n",
        "        return\n",
        "\n",
        "    def evaluate(self, dataset,target_user_n=1000,target_item_n=-1,rank_threshold=1,is_val=False):\n",
        "        \"\"\"Evaluate model on validation set or test set\n",
        "\n",
        "        Args:\n",
        "            dataset (:obj:`SASRecDataSet`): SASRecDataSet containing users-item interaction history.\n",
        "            target_user_n (int, optional): Number of randomly sampled users to evaluate. Defaults to 1000.\n",
        "            target_item_n (int, optional): Size of candidate. Defaults to -1, which means all.\n",
        "            rank_threshold (int, optional): k value in NDCG@k and HR@k. Defaults to 10.\n",
        "            is_val (bool, optional): If true, evaluate on validation set. If False, evaluate on test set. Defaults to False.\n",
        "\n",
        "        Returns:\n",
        "            float: NDCG@k\n",
        "            float: HR@k\n",
        "        \"\"\"\n",
        "\n",
        "        usernum = dataset.usernum\n",
        "        itemnum = dataset.itemnum\n",
        "        all = dataset.User\n",
        "        train = dataset.user_train  # removing deepcopy\n",
        "        valid = dataset.user_valid\n",
        "        test = dataset.user_test\n",
        "\n",
        "        NDCG = 0.0\n",
        "        HT = 0.0\n",
        "        valid_user = 0.0\n",
        "\n",
        "        if len(self.val_users) == 0:\n",
        "            self.sample_val_users(dataset,target_user_n)\n",
        "\n",
        "        for u in tqdm(self.val_users, ncols=70, leave=False, unit=\"b\"):\n",
        "\n",
        "            if len(train[u]) < 1 or len(test[u]) < 1:\n",
        "                continue\n",
        "\n",
        "            seq = np.zeros([self.seq_max_len], dtype=np.int32)\n",
        "            idx = self.seq_max_len - 1\n",
        "\n",
        "            if is_val:\n",
        "                item_idx = [valid[u][0]]\n",
        "            else:\n",
        "                seq[idx] = valid[u][0]\n",
        "                idx -= 1\n",
        "                item_idx = [test[u][0]]\n",
        "\n",
        "            for i in reversed(train[u]):\n",
        "                seq[idx] = i\n",
        "                idx -= 1\n",
        "                if idx == -1:\n",
        "                    break\n",
        "\n",
        "            rated = set(all[u])\n",
        "\n",
        "            if (target_item_n == -1):\n",
        "              item_idx=item_idx+list(set(range(1,itemnum+1)).difference(rated))\n",
        "\n",
        "            elif type(target_item_n)==int:\n",
        "              for _ in range(target_item_n):\n",
        "                t = np.random.randint(1, itemnum + 1)\n",
        "                while t in rated:\n",
        "                    t = np.random.randint(1, itemnum + 1)\n",
        "                item_idx.append(t)\n",
        "\n",
        "            elif type(target_item_n)==float:\n",
        "              for _ in range(round(itemnum*target_item_n)):\n",
        "                t = np.random.randint(1, itemnum + 1)\n",
        "                while t in rated:\n",
        "                    t = np.random.randint(1, itemnum + 1)\n",
        "                item_idx.append(t)\n",
        "\n",
        "            else:\n",
        "              raise\n",
        "\n",
        "            inputs = {}\n",
        "            inputs[\"user\"] = np.expand_dims(np.array([u]), axis=-1)\n",
        "            inputs[\"input_seq\"] = np.array([seq])\n",
        "            inputs[\"candidate\"] = np.array([item_idx])\n",
        "            # print(inputs)\n",
        "\n",
        "            # inverse to get descending sort\n",
        "            predictions = -1.0 * self.predict(inputs, len(item_idx)-1)\n",
        "            predictions = np.array(predictions)\n",
        "            predictions = predictions[0]\n",
        "            # print('predictions:', predictions)\n",
        "\n",
        "            rank = predictions.argsort().argsort()[0]\n",
        "            # print('rank:', rank)\n",
        "\n",
        "            valid_user += 1\n",
        "\n",
        "            if rank < rank_threshold:\n",
        "                NDCG += 1 / np.log2(rank + 2)\n",
        "                HT += 1\n",
        "\n",
        "        return NDCG / valid_user, HT / valid_user\n",
        "\n",
        "    def recommend_item(self, dataset, user_map_dict,user_id_list, target_item_n=-1,top_n=10,exclude_purchased=True,is_test=False):\n",
        "        \"\"\"Recommend items to user\n",
        "\n",
        "        Args:\n",
        "            dataset (:obj:`util.SASRecDataSet`): SASRecDataSet containing users-item interaction history.\n",
        "            user_map_dict (dict): Dict { user_id : encoded_user_label , ... }\n",
        "            user_id_list (list): User list to predict.\n",
        "            target_item_n (int, optional): Size of candidate. Defaults to -1, which means all.\n",
        "            top_n (int, optional): Number of items to recommend. Defaults to 10.\n",
        "            exclude_purchased (bool, optional): If true, exclude already purchased item from candidate. Defaults to True.\n",
        "            is_test (bool, optional): If true, exclude the last item from each user's sequence. Defaults to False.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: recommended items for users\n",
        "        \"\"\"\n",
        "        all = dataset.User\n",
        "        itemnum = dataset.itemnum\n",
        "        users = [user_map_dict[u] for u in user_id_list]\n",
        "        inv_user_map = {v: k for k, v in user_map_dict.items()}\n",
        "        return_dict={}\n",
        "\n",
        "        for u in tqdm(users):\n",
        "            seq = np.zeros([self.seq_max_len], dtype=np.int32)\n",
        "            idx = self.seq_max_len - 1\n",
        "\n",
        "            list_to_seq = all[u] if not is_test else all[u][:-1]\n",
        "            for i in reversed(list_to_seq):\n",
        "                seq[idx] = i\n",
        "                idx -= 1\n",
        "                if idx == -1:\n",
        "                    break\n",
        "\n",
        "            if exclude_purchased:\n",
        "                rated = set(all[u])\n",
        "            else:\n",
        "                rated = set()\n",
        "\n",
        "            # make empty candidate list\n",
        "            item_idx=[]\n",
        "\n",
        "            if (target_item_n == -1):\n",
        "                item_idx=item_idx+list(set(range(1,itemnum+1)).difference(rated))\n",
        "\n",
        "            elif type(target_item_n)==int:\n",
        "                for _ in range(target_item_n):\n",
        "                    t = np.random.randint(1, itemnum + 1)\n",
        "                    while t in rated:\n",
        "                        t = np.random.randint(1, itemnum + 1)\n",
        "                    item_idx.append(t)\n",
        "\n",
        "            elif type(target_item_n)==float:\n",
        "                for _ in range(round(itemnum*target_item_n)):\n",
        "                    t = np.random.randint(1, itemnum + 1)\n",
        "                    while t in rated:\n",
        "                        t = np.random.randint(1, itemnum + 1)\n",
        "                    item_idx.append(t)\n",
        "\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "            inputs = {}\n",
        "            inputs[\"user\"] = np.expand_dims(np.array([u]), axis=-1)\n",
        "            inputs[\"input_seq\"] = np.array([seq])\n",
        "            inputs[\"candidate\"] = np.array([item_idx])\n",
        "\n",
        "            predictions = self.predict(inputs, len(item_idx)-1)\n",
        "            predictions = np.array(predictions)\n",
        "            predictions = predictions[0]\n",
        "\n",
        "            pred_dict = {v : predictions[i] for i,v in enumerate(item_idx)}\n",
        "            pred_dict = sorted(pred_dict.items(), key = lambda item: item[1], reverse = True)\n",
        "            top_list = pred_dict[:top_n]\n",
        "\n",
        "            return_dict[inv_user_map[u]] = top_list\n",
        "\n",
        "        return return_dict\n",
        "\n",
        "    def old_get_user_item_score(self, dataset, user_map_dict,item_map_dict,user_id_list, item_list,is_test=False):\n",
        "        \"\"\"\n",
        "        Deprecated\n",
        "        \"\"\"\n",
        "        all = dataset.User\n",
        "        users = [user_map_dict[u] for u in user_id_list]\n",
        "        items = [item_map_dict[i] for i in item_list]\n",
        "        # inv_user_map = {v: k for k, v in user_map_dict.items()}\n",
        "        # inv_item_map = {v: k for k, v in item_map_dict.items()}\n",
        "        score_dict = {i:[] for i in item_list}\n",
        "\n",
        "        for u in tqdm(users,unit=' User',desc='Getting Scores for each user ...'):\n",
        "\n",
        "            seq = np.zeros([self.seq_max_len], dtype=np.int32)\n",
        "            idx = self.seq_max_len - 1\n",
        "\n",
        "            list_to_seq = all[u] if not is_test else all[u][:-1]\n",
        "            for i in reversed(list_to_seq):\n",
        "                seq[idx] = i\n",
        "                idx -= 1\n",
        "                if idx == -1:\n",
        "                    break\n",
        "\n",
        "            inputs = {}\n",
        "            inputs[\"user\"] = np.expand_dims(np.array([u]), axis=-1)\n",
        "            inputs[\"input_seq\"] = np.array([seq])\n",
        "            inputs[\"candidate\"] = np.array([items])\n",
        "\n",
        "            predictions = self.predict(inputs, len(items)-1)\n",
        "            predictions = np.array(predictions)\n",
        "            predictions = predictions[0]\n",
        "\n",
        "            # pred_dict = {inv_item_map[v] : predictions[i] for i,v in enumerate(items)}\n",
        "\n",
        "            for i,v in enumerate(item_list):\n",
        "                score_dict[v].append(predictions[i])\n",
        "\n",
        "        return_df = pd.DataFrame({\n",
        "            'user_id':user_id_list,\n",
        "        })\n",
        "\n",
        "        for k in score_dict:\n",
        "            return_df[k] = score_dict[k]\n",
        "\n",
        "        return_df = return_df.sort_values(by='user_id').reset_index(drop=True)\n",
        "\n",
        "        return return_df\n",
        "\n",
        "    def get_user_item_score(self,dataset,user_id_list, item_list,user_map_dict,item_map_dict,batch_size=128):\n",
        "        \"\"\"Get item score for each user on batch\n",
        "\n",
        "        Args:\n",
        "            dataset (:obj:`SASRecDataSet`): SASRecDataSet containing users-item interaction history.\n",
        "            user_id_list (list): User list to predict.\n",
        "            item_list (list): Item list to predict\n",
        "            user_map_dict (dict): Dict { user_id : encoded_user_label , ... }\n",
        "            item_map_dict (dict): Dict { item : encoded_item_label , ... }\n",
        "            batch_size (int, optional): Batch size. Defaults to 128.\n",
        "\n",
        "        Raises:\n",
        "            Exception: Batch_size must be smaller than user id list size.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: user-item score\n",
        "        \"\"\"\n",
        "\n",
        "        if batch_size >= len(user_id_list):\n",
        "            raise Exception('batch_size must be smaller than user_id_list size')\n",
        "\n",
        "        user_history = dataset.User\n",
        "        inv_user_map = {v: k for k, v in user_map_dict.items()}\n",
        "        cand = [item_map_dict[i] for i in item_list]\n",
        "\n",
        "        if len(user_id_list)%batch_size ==0:\n",
        "            num_steps = int(len(user_id_list)/batch_size)\n",
        "        else:\n",
        "            num_steps = int(len(user_id_list)/batch_size) + 1\n",
        "        # num_steps = len(user_id_list)/batch_size\n",
        "        # num_steps = num_steps if num_steps%1 == 0 else int(num_steps)+1\n",
        "        print(num_steps)\n",
        "        score_dict = dict()\n",
        "\n",
        "        start_index=0\n",
        "\n",
        "        for step in tqdm(\n",
        "                range(num_steps), leave=True, unit=\"batch\",\n",
        "            ):\n",
        "\n",
        "            # get user batch\n",
        "            u = user_id_list[start_index:start_index+batch_size] if step != num_steps-1 \\\n",
        "                else user_id_list[start_index:]\n",
        "\n",
        "            start_index+=batch_size\n",
        "\n",
        "            u = [user_map_dict[user] for user in u]\n",
        "\n",
        "            # get sequence batch\n",
        "            seq = [user_history[user] for user in u]\n",
        "\n",
        "            inputs = self.create_combined_dataset_pred(tuple(u),tuple(seq),cand)\n",
        "            # print(inputs)\n",
        "\n",
        "            predictions = self.batch_predict(inputs, len(cand)-1)\n",
        "            predictions = np.array(predictions)\n",
        "\n",
        "            for i in range(len(u)):\n",
        "                score_dict[inv_user_map[u[i]]]=predictions[i]\n",
        "\n",
        "\n",
        "        return_df = pd.DataFrame(list(score_dict.items()),columns = ['user_id','score_array']).set_index('user_id',drop=True)\n",
        "        # print(return_df)\n",
        "        return_df[item_list] = pd.DataFrame(return_df['score_array'].tolist(), index= return_df.index)\n",
        "        return_df = return_df.drop('score_array',axis=1).reset_index().sort_values(by='user_id').reset_index(drop=True)\n",
        "\n",
        "        return return_df\n",
        "\n",
        "\n",
        "    def create_combined_dataset_pred(self,u,seq,cand):\n",
        "        \"\"\"\n",
        "        function to create model inputs from sampled batch data.\n",
        "        This function is used during predicting on batch.\n",
        "        \"\"\"\n",
        "        inputs = {}\n",
        "        seq = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "            seq, padding=\"pre\", truncating=\"pre\", maxlen=self.seq_max_len\n",
        "        )\n",
        "\n",
        "        inputs[\"users\"] = np.expand_dims(np.array(u), axis=-1)\n",
        "        inputs[\"input_seq\"] = seq\n",
        "        inputs['candidate'] = np.array([cand])\n",
        "\n",
        "        return inputs\n",
        "\n",
        "\n",
        "    def batch_predict(self, inputs,cand_n):\n",
        "        \"\"\"Returns the logits for the item candidates.\n",
        "\n",
        "        Args:\n",
        "            inputs (tf.Tensor): Input tensor.\n",
        "            cand_n (int): Num of candidates.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: Output tensor\n",
        "        \"\"\"\n",
        "        training = False\n",
        "        input_seq = inputs[\"input_seq\"]\n",
        "        candidate = inputs[\"candidate\"]\n",
        "\n",
        "        mask = tf.expand_dims(tf.cast(tf.not_equal(input_seq, 0), tf.float32), -1)\n",
        "        seq_embeddings, positional_embeddings = self.embedding(input_seq)\n",
        "        seq_embeddings += positional_embeddings\n",
        "        # seq_embeddings = self.dropout_layer(seq_embeddings)\n",
        "        seq_embeddings *= mask\n",
        "        seq_attention = seq_embeddings\n",
        "        seq_attention = self.encoder(seq_attention, training, mask)\n",
        "        seq_attention = self.layer_normalization(seq_attention)  # (b, s, d)\n",
        "        seq_emb = tf.reshape(\n",
        "            seq_attention,\n",
        "            [tf.shape(input_seq)[0] * self.seq_max_len, self.embedding_dim],\n",
        "        )  # (b*s, d)\n",
        "        # print(candidate)\n",
        "        candidate_emb = self.item_embedding_layer(candidate)  # (b, s, d)\n",
        "        candidate_emb = tf.transpose(candidate_emb, perm=[0, 2, 1])  # (b, d, s)\n",
        "\n",
        "        test_logits = tf.matmul(seq_emb, candidate_emb)\n",
        "        # (200, 100) * (1, 101, 100)'\n",
        "\n",
        "        test_logits = tf.reshape(\n",
        "            test_logits,\n",
        "            [tf.shape(input_seq)[0], self.seq_max_len, 1+cand_n],\n",
        "        )  # (1, 50, 1+can)\n",
        "        test_logits = test_logits[:, -1, :]  # (1, 101)\n",
        "        return test_logits\n",
        "\n",
        "\n",
        "    def save(self,path, exp_name='sas_experiment'):\n",
        "        \"\"\"Save trained SASRec Model\n",
        "\n",
        "        Args:\n",
        "            path (str): Path to save model.\n",
        "            exp_name (str): Experiment name.\n",
        "\n",
        "        Examples:\n",
        "            >>> model.save(path, exp_name)\n",
        "        \"\"\"\n",
        "\n",
        "        # make dir\n",
        "        if not os.path.exists(f'{path}/{exp_name}'):\n",
        "            os.mkdir(f'{path}/{exp_name}')\n",
        "\n",
        "        self.save_weights(f'{path}/{exp_name}/{exp_name}_weights') # save trained weights\n",
        "        arg_list = ['item_num','seq_max_len','num_blocks','embedding_dim','attention_dim','attention_num_heads','dropout_rate','conv_dims','l2_reg','history']\n",
        "        dict_to_save = {a: self.__dict__[a] for a in arg_list}\n",
        "\n",
        "        with open(f'{path}/{exp_name}/{exp_name}_model_args','wb') as f:\n",
        "            pickle.dump(dict_to_save, f)\n",
        "\n",
        "        if not os.path.isfile(f'{path}/{exp_name}/{exp_name}_save_log.txt'):\n",
        "            with open(f'{path}/{exp_name}/{exp_name}_save_log.txt','w') as f:\n",
        "                f.writelines(f'Model args: {dict_to_save}\\n')\n",
        "                f.writelines(f'[epoch {self.epoch}] Best HR@10 score: {self.best_score}\\n')\n",
        "        else:\n",
        "            with open(f'{path}/{exp_name}/{exp_name}_save_log.txt','a') as f:\n",
        "                f.writelines(f'[epoch {self.epoch}] Best HR@10 score: {self.best_score}\\n')\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "    def sample_val_users(self,dataset,target_user_n):\n",
        "        \"\"\"Sample users for validation\n",
        "\n",
        "        Args:\n",
        "            dataset (:obj:`SASRecDataSet`): SASRec dataset used for training\n",
        "            target_user_n (int): Number of users to sample\n",
        "        \"\"\"\n",
        "        usernum = dataset.usernum\n",
        "        if usernum > target_user_n:\n",
        "            self.val_users = random.sample(range(1, usernum + 1), target_user_n)\n",
        "        else:\n",
        "            self.val_users = range(1, usernum + 1)\n"
      ],
      "metadata": {
        "id": "BZdA-TzWVFlv"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(data_test,target_user_n=1000,target_item_n=-1,rank_threshold=10,is_val=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SujoeGAeU72-",
        "outputId": "fa1f7dcc-297f-408a-fdef-3a8426ce7ac0"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.12494044136283879, 0.14506172839506173)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "6b934cfe6803ab1b417b23087ee3002e94bb134aa34c5e5fe78916216a69e86b"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}